<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<!-- saved from url=(0044)https://cs.nyu.edu/~fergus/pmwiki/pmwiki.php -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	<title>Ning Xu - Publications </title>
	<meta http-equiv="Content-Style-Type" content="text/css">
	<!--HTMLHeader--><style type="text/css">
	<!--
  ul, ol, pre, dl, p { margin-top:0px; margin-bottom:0px; }
  code.escaped { white-space: nowrap; }
  .vspace { margin-top:1.33em; }
  .indent { margin-left:40px; }
  .outdent { margin-left:40px; text-indent:-40px; }
  a.createlinktext { text-decoration:none; border-bottom:1px dotted gray; }
  a.createlink { text-decoration:none; position:relative; top:-0.5em;
    font-weight:bold; font-size:smaller; border-bottom:none; }
  img { border:0px; }
  .editconflict { color:green; 
  font-style:italic; margin-top:1.33em; margin-bottom:1.33em; }

  table.markup { border:2px dotted #ccf; width:90%; }
  td.markup1, td.markup2 { padding-left:10px; padding-right:10px; }
  table.vert td.markup1 { border-bottom:1px solid #ccf; }
  table.horiz td.markup1 { width:23em; border-right:1px solid #ccf; }
  table.markup caption { text-align:left; }
  div.faq p, div.faq pre { margin-left:2em; }
  div.faq p.question { margin:1em 0 0.75em 0; font-weight:bold; }
  div.faqtoc div.faq * { display:none; }
  div.faqtoc div.faq p.question 
    { display:block; font-weight:normal; margin:0.5em 0 0.5em 20px; line-height:normal; }
  div.faqtoc div.faq p.question * { display:inline; }
   
    .frame 
      { border:1px solid #cccccc; padding:4px; background-color:#f9f9f9; }
    .lfloat { float:left; margin-right:0.5em; }
    .rfloat { float:right; margin-left:0.5em; }
a.varlink { text-decoration:none; }

-->
	</style>  <meta name="robots" content="index,follow">

	<link rel="stylesheet" href="https://ningxu1990.github.io/Ning_Xu_files/pmwiki.css" type="text/css">
<style type="text/css">
<!--
#header {background-color: #134A86;}
a:link, a:visited, #menu ul li .here a, #menu ul li .here a:hover {color: #134A86;}
-->
</style>
<!--[if lte IE 6]>
<style type="text/css">
img, #logo, #vis, #header { behavior: url("https://cs.nyu.edu/~fergus/pmwiki/pub/skins/simpletab/iepngfix.htc"); }
</style>
<![endif]-->
	
</head><body><div id="page"><div id="suptitle"></div>
  <img src="https://ningxu1990.github.io/Ning_Xu_files/head.png" alt="" width="858" height="60" />  


<div id="sidebar"><ul><li><a class="selflink" href="https://ningxu1990.github.io">Home</a>
<div class="vspace"></div></li>
<li><a class="wikilink" href="https://ningxu1990.github.io/Research">Research</a></li>
<li><a class="wikilink" href="https://ningxu1990.github.io/Publications">Publications</a></li>
<li><a class="wikilink" href="https://ningxu1990.github.io/Students">Students</a></li>
<li><a class="wikilink" href="https://ningxu1990.github.io/Teaching">Teaching</a></li>
<li><a class="wikilink" href="https://ningxu1990.github.io/Bio">Bio</a></li></ul>
</div>
	
	<div id="content"><!--PageText-->
<div id="wikitext">
  <div class="vspace"></div>

<h1>Publications</h1>
<p align="justify">My papers can be found at:  
<a class="urllink" href="https://scholar.google.com/citations?hl=en&user=okruzyMAAAAJ&view_op=list_works&gmla=AJsN-F5l4NXzfcLjKR2qPq8zpoViMwbZSgnS87Fh_Ijss0DFtS-v0NQWcrlNFzuuTkicoZV_2xeqVQF3KV4HRP9AAFU_6GeadIMccfApcvOQEIZB0T3WShY" rel="nofollow">Google Scholar</a> 
<br>
<br>

<hr>
<strong><font color="#2127AE" size="3px">Journal Articles</font></strong>
<ul>
  <br>

        <li><strong>Multi-modal Validation and Domain Interaction Learning for Knowledge-based Visual Question Answering. </strong> <a href="https://ieeexplore.ieee.org/document/10496907" target="_blank" rel="external">[PDF]</a><br />
          <em><strong>Ning Xu</strong>, Yifei Gao, An-An Liu*, Hongshuo Tian, Yongdong Zhang. </em><br />
        IEEE Transactions on Knowledge and Data Engineering, 2024.</li>
	    <br>
		
        <li><strong>Learning to Supervise Knowledge Retrieval over a Tree Structure for Visual Question Answering. </strong> <a href="https://ieeexplore.ieee.org/abstract/document/10404060" target="_blank" rel="external">[PDF]</a><br />
          <em><strong>Ning Xu</strong>, Zimu Lu, Hongshuo Tian, Rongbao Kang, Jinbo Cao, Yongdong Zhang, An-An Liu*. </em><br />
        IEEE Transactions on Multimedia, vol. 26, pp. 6689-6700, 2024.</li>
	    <br>
		
        <li><strong>Event-aware Retrospective Learning for Knowledge-based Image Captioning. </strong> <a href="https://ieeexplore.ieee.org/document/10297411" target="_blank" rel="external">[PDF]</a><br />
          <em>An-An Liu, Yingchen Zhai, <strong>Ning Xu*</strong>, Hongshuo Tian, Weizhi Nie, Yongdong Zhang. </em><br />
        IEEE Transactions on Multimedia, vol. 26, pp. 4898-4911, 2024.</li>
	    <br>
		
        <li><strong>Counterfactual Visual Dialog: Robust Commonsense Knowledge Learning from Unbiased Training. </strong> <a href="https://ieeexplore.ieee.org/document/10147343" target="_blank" rel="external">[PDF]</a><br />
          <em>An-An Liu, Chenxi Huang, <strong>Ning Xu*</strong>, Hongshuo Tian, Jing Liu, Yongdong Zhang. </em><br />
        IEEE Transactions on Multimedia, vol. 26, pp. 1639-1651, 2024.</li>
	    <br>

	    <li><strong>Prior knowledge guided text to image generation. </strong> 
		  <a href="https://www.sciencedirect.com/science/article/pii/S0167865523003501" target="_blank" rel="external">[PDF]</a><br>
            <em>An-An Liu, Zefang Sun, <strong>Ning Xu*</strong>, Rongbao Kang, Jinbo Cao, Fan Yang, Weijun Qin, Shenyuan Zhang, Xuanya Li. </em><br>
        Pattern Recognition Letters, vol. 177, pp. 89-95, 2024.</li>
	    <br>
		
	    <li><strong>Exploring visual relationship for social media popularity prediction. </strong> 
		  <a href= "https://www.sciencedirect.com/science/article/abs/pii/S1047320322002589" target="_blank" rel="external">[PDF]</a><br>
            <em>An-An Liu, Hongwei Du, <strong>Ning Xu*</strong>, Quan Zhang, Shenyuan Zhang, Yejun Tang, Xuanya Li. </em><br>
        Journal of Visual Communication and Image Representation, vol. 90, 103738, 2023.</li>
	    <br>

        <li><strong>CD-GAN: Commonsense-Driven Generative Adversarial Network with Hierarchical Refinement for Text-to-Image Synthesis. </strong> <a href="https://spj.science.org/doi/10.34133/icomputing.0017" rel="external">[PDF]</a><br />
          <em>Guokai Zhang, <strong>Ning Xu*</strong>, Chenggang Yan, Bolun Zheng, Yulong Duan, Bo Lv, An-An Liu. </em><br />
        Intelligent Computing, vol. 2, 0017, 2023.</li>
	    <br>

	    <li><strong>Multi-stage reasoning on introspecting and revising bias for visual question answering. </strong> 
		  <a href= https://www.researchgate.net/publication/373472727_Multi-stage_reasoning_on_introspecting_and_revising_bias_for_visual_question_answering" target="_blank" rel="external">[PDF]</a><br>
            <em>An-An Liu, Zimu Lu, <strong>Ning Xu</strong>, Min Liu, Chenggang Yan, Bolun Zheng, Bo Lv, Yulong Duan, Zhuang Shao, Xuanya Li*. </em><br>
        ACM Transactions on the Web, 2023.</li>
	    <br>
		
        <li><strong>A Comprehensive Survey on Deep-Learning-Based Visual Captioning. </strong> <a href="https://link.springer.com/article/10.1007/s00530-023-01175-x" rel="external">[PDF]</a><br />
          <em>Bowen Xin, <strong>Ning Xu*</strong>, Yingchen Zhai, Tingting Zhang, Zimu Lu, Jing Liu, Weizhi Nie, Xuanya Li, An-An Liu. </em><br />
        Multimedia Systems, vol. 29, no. 6, pp. 3781-3804, 2023.</li>
	    <br>
				
        <li><strong>SMPC: Boosting Social Media Popularity Prediction with Caption. </strong> <a href="https://dl.acm.org/doi/10.1007/s00530-022-01030-5" rel="external">[PDF]</a><br />
          <em>An-An Liu, Xiaowen Wang, <strong>Ning Xu*</strong>, Jing Liu, Yuting Su, Quan Zhang, Shenyuan Zhang, Yejun Tang, Junbo Guo, Guoqing Jin, Xuanya Li*. </em><br />
        Multimedia Systems, vol. 29, no. 2, pp. 577-586, 2023.</li>
	    <br>
		
        <li><strong>High-Order Interaction Learning for Image Captioning. </strong> <a href="https://ieeexplore.ieee.org/document/9579002" rel="external">[PDF]</a><br />
          <em>Yanhui Wang, <strong>Ning Xu*</strong>, An-An Liu*, Wenhui Li, Yongdong Zhang. </em><br />
        IEEE Transactions on Circuits and Systems for Video Technology, vol. 32, no. 7, pp. 4417-4430, 2022.</li>
	    <br>
		
        <li><strong>Region-Aware Image Captioning via Interaction Learning. </strong> <a href="https://ieeexplore.ieee.org/document/9521159" target="_blank" rel="external">[PDF]</a><br />
          <em>An-An Liu, Yingchen Zhai, <strong>Ning Xu*</strong>, Weizhi Nie, Wenhui Li*, Yongdong Zhang. </em><br />
        IEEE Transactions on Circuits and Systems for Video Technology, vol. 32, no. 6, pp. 3685-3696, 2022.</li>
	    <br>

        <li><strong>Closed-loop reasoning with graphâ€‘aware dense interaction for visual dialog. </strong> <a href="https://dl.acm.org/doi/10.1007/s00530-022-00947-1" rel="external">[PDF]</a><br />
          <em>An-An Liu, Guokai Zhang, <strong>Ning Xu*</strong>, Junbo Guo, Guoqing Jin, Xuanya Li. </em><br />
        Multimedia Systems, vol. 28, no. 5, pp. 1823-1832, 2022.</li>
	    <br>
		
	    <li><strong>A review of feature fusion-based media popularity prediction methods. </strong> 
		  <a href="https://www.x-mol.com/paper/1552432502740774912?adv" target="_blank" rel="external">[PDF]</a><br />
            <em>An-An Liu, Xiaowen Wang, <strong>Ning Xu*</strong>, Junbo Guo, Guoqing Jin, Quan Zhang, Yejun Tang, Shenyuan Zhang. </em><br />
        Visual Informatics, vol. 6, no. 4, pp. 78-89, 2022.</li>
        <br>

        <li><strong>Toward Region-Aware Attention Learning for Scene Graph Generation. </strong> <a href="https://ieeexplore.ieee.org/document/9461168" target="_blank" rel="external">[PDF]</a><br />
          <em>An-An Liu, Hongshuo Tian, <strong>Ning Xu*</strong>, Weizhi Nie, Yongdong Zhang, M. Kankanhalli. </em><br />
        IEEE Transactions on Neural Networks and Learning Systems, vol. 33, no. 12, pp. 7655-7666, 2022.</li>
	    <br>
		
        <li><strong>Multi-type decision fusion network for visual Q&A. </strong> <a href="https://www.sciencedirect.com/science/article/abs/pii/S0262885621001864" rel="external">[PDF]</a><br />
          <em>An-An Liu, Zimu Lu, <strong>Ning Xu*</strong>, Weizhi Nie, Wenhui Li*. </em><br />
        Image and Vision Computing, vol. 115, 104281, 2021.</li>
	    <br>

        <li><strong>Scene-Graph-Guided message passing network for dense captioning. </strong> <a href="https://www.sciencedirect.com/science/article/abs/pii/S016786552100043X" target="_blank" rel="external">[PDF]</a><br />
          <em>An-An Liu, Yanhui Wang, <strong>Ning Xu*</strong>, Shan Liu, Xuanya Li*. </em><br />
        Pattern Recognition Letters, vol. 145, pp. 187-193, 2021.</li>
	    <br>

	    <li><strong>Coupled-dynamic learning for vision and language: Exploring Interaction between different tasks. </strong> 
		  <a href="https://www.sciencedirect.com/science/article/abs/pii/S0031320321000169" target="_blank" rel="external">[PDF]</a><br />
            <em><strong>Ning Xu</strong>, Hongshuo Tian, Yanhui Wang, Weizhi Nie, Dan Song, An-An Liu*, Wu Liu. </em><br />
        Pattern Recognition, vol. 113, 107829, 2021.</li>
        <br>

	    <li><strong>Image Captioning with multi-level similarity-guided semantic matching. </strong> 
		  <a href="https://www.sciencedirect.com/science/article/pii/S2468502X21000590" target="_blank" rel="external">[PDF]</a><br />
            <em>Jiesi Li, <strong>Ning Xu*</strong>, Weizhi Nie, Shenyuan Zhang. </em><br />
        Visual Informatics, vol. 5, no. 4, pp. 41-48, 2021.</li>
        <br>

        <li><strong>Adaptively Clustering-Driven Learning for Visual Relationship Detection. </strong> <a href="https://ieeexplore.ieee.org/document/9290418" target="_blank" rel="external">[PDF]</a><br />
          <em>An-An Liu, Yanhui Wang, <strong>Ning Xu*</strong>, Weizhi Nie, Jie Nie*, Yongdong Zhang. </em><br />
        IEEE Transactions on Multimedia, vol. 23, pp. 4515-4525, 2021.</li>
	    <br>

        <li><strong>Scene Graph Inference via Multi-Scale Context Modeling. </strong> <a href="https://ieeexplore.ieee.org/document/9079879" target="_blank" rel="external">[PDF]</a><br />
          <em><strong>Ning Xu</strong>, An-An Liu*, Yongkang Wong, Weizhi Nie, Yuting Su, Mohan Kankanhalli. </em><br />
        IEEE Transactions on Circuits and Systems for Video Technology, vol. 31, no. 3, pp. 1031-1041, 2021.</li>
	    <br>
		
        <li><strong>Multi-Level Policy and Reward-Based Deep Reinforcement Learning Framework for Image Captioning. </strong> <a href="https://ieeexplore.ieee.org/document/8844130" target="_blank" rel="external">[PDF]</a><br />
          <em><strong>Ning Xu</strong>, Hanwang Zhang, An-An Liu*, Weizhi Nie, Yuting Su, Jie Nie*, Yongdong Zhang. </em><br />
        IEEE Transactions on Multimedia, vol. 22, no. 5, pp. 1372-1383, 2020.</li>
	    <br>

	    <li><strong>Hierarchical Deep Neural Network for Image Captioning. </strong> 
		  <a href="https://link.springer.com/content/pdf/10.1007%2Fs11063-019-09997-5.pdf" target="_blank" rel="external">[PDF]</a><br>
            <em>Yuting Su, Yuqian Li, <strong>Ning Xu</strong>*, An-An Liu*. </em><br>
        Neural Processing Letters, vol. 52, no. 2, pp. 1057-1067, 2020.<br />
          <br />
		  
        <li><strong>Dual-Stream Recurrent Neural Network for Video Captioning. </strong> <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8447210" target="_blank" rel="external">[PDF]</a><br />
          <em><strong>Ning Xu</strong>, An-An Liu*, Yongkang Wong, Yongdong Zhang, Weizhi Nie, Yuting Su, Mohan S. Kankanhalli. </em><br />
        IEEE Transactions on Circuits and Systems for Video Technology, vol. 29, no. 8, pp. 2482-2493, 2019.</li>
	    <br>
		  
	    <li><strong>Multi-Guiding Long-Short Term Memory for Video Captioning. </strong> 
		  <a href="https://link.springer.com/article/10.1007%2Fs00530-018-0598-5" target="_blank" rel="external">[PDF]</a><br>
            <em><strong>Ning Xu</strong>, An-An Liu*, Weizhi Nie*, Yuting Su. </em><br>
        Multimedia Systems,  vol. 25, no. 6, pp. 663-672, 2019. <em></em></li>
	    <br>

	    <li><strong>Multi-Domain and Multi-Task Learning for Human Action Recognition. </strong> 
		  <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8476540" target="_blank" rel="external">[PDF]</a><br>
            <em>An-An Liu*, <strong>Ning Xu*</strong>, Weizhi Nie*, Yuting Su, Yongdong Zhang. </em><br>
        IEEE Transactions on Image Processing, vol. 28, no. 2, pp. 853-867, 2019.</li>
	    <br>
		  
	    <li><strong>Scene graph captioner: Image captioning based on structural visual representation. </strong> 
		  <a href= https://www.sciencedirect.com/science/article/abs/pii/S1047320318303535" target="_blank" rel="external">[PDF]</a><br>
            <em><strong>Ning Xu</strong>, An-An Liu*, Jing Liu*, Weizhi Nie, Yuting Su. </em><br>
        Journal of Visual Communication and Image Representation, vol. 58, pp. 477-485, 2019.</li>
	    <br>

	    <li><strong>Attention-in-Attention Networks for Surveillance Video Understanding in Internet of Things. </strong> 
		  <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8141866" target="_blank" rel="external">[PDF]</a><br>
            <em><strong>Ning Xu</strong>, An-An Liu*, Weizhi Nie, Yuting Su. </em><br>
        IEEE Internet of Things Journal, vol. 5, no. 5, pp. 3419-3429, 2018.</li>
	    <br>
		  
	    <li><strong>Hierarchical &amp; Multimodal Video Captioning: Discovering and Transferring Multimodal Knowledge for Vision to Language. </strong> 
		  <a href="http://www.sciencedirect.com/science/article/pii/S1077314217300735/pdfft?md5=4b8580ed4f56eb06185af1c0ea1cc6b5&pid=1-s2.0-S1077314217300735-main.pdf" target="_blank" rel="external">[PDF]</a><br>
            <em>An-An Liu*, <strong>Ning Xu</strong>, Yongkang Wong, Junnan Li, Yuting Su, Mohan S. Kankanhalli. </em><br>
        Computer Vision and Image Understanding, vol. 163, pp. 113-125, 2017.</li>
	    <br>
		  
        <li><strong>Benchmarking a Multimodal and Multiview and Interactive Dataset for Human Action Recognition. </strong> 
		  <a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7515012" target="_blank" rel="external">[PDF]</a><br />
          <em>An-An Liu*, <strong>Ning Xu</strong>, Weizhi Nie, Yuting Su*, Yongkang Wong, Mohan S. Kankanhalli. </em><br />
        IEEE Transactions on Cybernetics, vol. 47, no. 7, pp. 1781-1794, 2017.</li>
	    <br>
		  
        <li><strong>Single/multi-view human action recognition via regularized multi-task learning. </strong> 
		  <a href="https://ac.els-cdn.com/S0925231214013885/1-s2.0-S0925231214013885-main.pdf?_tid=af7489bc-e490-11e7-b3a1-00000aab0f01&acdnat=1513669753_ede107059bae358242aa059181fafba9" target="_blank" rel="external">[PDF]</a><br />
          <em>An-An Liu, <strong>Ning Xu</strong>, Yuting Su, Hong Lin, Tong Hao, Zhaoxuan Yang. </em><br />
        Neurocomputing, vol. 151, pp. 544-553, 2014.</li>
          </ul>
		  
       
		<br>
		<strong><font color="#2127AE" size="3px">Conference Papers</font></strong><br>
		<br>
           <ul>
		   
           <li><strong>Towards Confidence-Aware Commonsense Knowledge Integration for Scene Graph Generation. </strong> 
		   <a href="https://www.computer.org/csdl/proceedings-article/icme/2023/689100c255/1PTMFhxIJqM" target="_blank" rel="external">[PDF]</a><br />
               <em>Hongshuo Tian, <strong>Ning Xu*</strong>, Yanhui Wang, Chenggang Yan, Bolun Zheng, Xuanya Li, An-An Liu*. </em><br />
             ICME, pp. 2255-2260, 2023.  <em>(CCF-B)</em></li>
           <br>
		   
           <li><strong>Knowledge Prompt Makes Composed Pre-Trained Models Zero-Shot News Captioner. </strong> 
		   <a href="https://www.computer.org/csdl/proceedings-article/icme/2023/689100c879/1PTNnlDItMY" target="_blank" rel="external">[PDF]</a><br />
               <em>Yanhui Wang, <strong>Ning Xu</strong>, Hongshuo Tian, Bo Lv, YuLong Duan, Xuanya Li*, An-An Liu. </em><br />
             ICME, pp. 2879-2884, 2023.  <em>(CCF-B)</em></li>
           <br>

           <li><strong>Triangle-Reward Reinforcement Learning: A Visual-Linguistic Semantic Alignment for Image Captioning. </strong> 
		   <a href="https://dl.acm.org/doi/10.1145/3474085.3475604" target="_blank" rel="external">[PDF]</a><br />
               <em>Weizhi Nie, Jiesi Li, <strong>Ning Xu*</strong>, An-An Liu*, Xuanya Li, Yongdong Zhang. </em><br />
             ACM Multimedia, pp. 4510-4518, 2021.  <em>(CCF-A)</em></li>
           <br>
		   
           <li><strong>Mask and Predict: Multi-step Reasoning for Scene Graph Generation. </strong> 
		   <a href="https://dl.acm.org/doi/10.1145/3474085.3475545" target="_blank" rel="external">[PDF]</a><br />
               <em>Hongshuo Tian, <strong>Ning Xu*</strong>, An-An Liu*, Chenggang Yan, Zhendong Mao, Quan Zhang, Yongdong Zhang. </em><br />
             ACM Multimedia, pp. 4128-4136, 2021.  <em>(CCF-A)</em></li>
           <br>
		   
           <li><strong>Self-Attention Graph Residual Convolutional Networks for Event Detection with dependency relations. </strong> 
		   <a href="https://aclanthology.org/2021.findings-emnlp.28/" target="_blank" rel="external">[PDF]</a><br />
               <em>An-An Liu*, <strong>Ning Xu*</strong>, Haozhe Liu. </em><br />
             EMNLP (Findings), pp. 302-311, 2021.  <em>(CCF-B)</em></li>
           <br>
		   
           <li><strong>Part-Aware Interactive Learning for Scene Graph Generation. </strong> 
		   <a href="https://dl.acm.org/doi/10.1145/3394171.3413501" target="_blank" rel="external">[PDF]</a><br />
               <em>Hongshuo Tian, <strong>Ning Xu*</strong>, An-An Liu*, Yongdong Zhang. </em><br />
             ACM Multimedia, pp. 3155-3163, 2020.  <em>(CCF-A)</em></li>
           <br>
		   
           <li><strong>Multi-Level Policy and Reward Reinforcement Learning for Image Captioning. </strong> 
		   <a href="https://www.ijcai.org/proceedings/2018/114" target="_blank" rel="external">[PDF]</a><br />
               <em>An-An Liu*, <strong>Ning Xu</strong>, Hanwang Zhang, Weizhi Nie, Yuting Su, Yongdong Zhang. </em><br />
             IJCAI, pp. 821-827, 2018.  <em>(CCF-A)</em></li>
           <br>
		   
           <li><strong>A Multi-modal &amp; Multi-view &amp; Interactive Benchmark Dataset for Human Action Recognition. </strong> 
		   <a href="http://delivery.acm.org/10.1145/2810000/2806315/p1195-xu.pdf?ip=202.113.11.104&id=2806315&acc=ACTIVE%20SERVICE&key=BF85BBA5741FDC6E%2EE4E04C281054793F%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&CFID=1018008020&CFTOKEN=25206131&__acm__=1513667603_35754e7fb63234465d9b5f7b2d537b36" target="_blank" rel="external">[PDF]</a><br />
               <em><strong>Ning Xu</strong>, An-An Liu*, Weizhi Nie, Yongkang Wong, Fuwu Li, Yuting Su. </em><br />
             ACM Multimedia, pp. 1195-1198, 2015.  <em>(CCF-A)</em></li>
           </ul>
		   
		<br>
		<strong><font color="#2127AE" size="3px">Techinical Reports</font></strong><br>
		<br>
          <ul>
		  
		  
		    <li><strong>TJU-NUS@TRECVID 2017: Video to Text Description. </strong> 
		    <a href="http://www-nlpir.nist.gov/projects/tvpubs/tv17.papers/tju.pdf" target="_blank" rel="external">[PDF]</a><br>
              <em>An-An Liu, Yurui Qiu, Yongkang Wong, <strong>Ning Xu</strong>, Yuting Su, Mohan S. Kankanhalli.</em><br>
            TRECVID Challenge Workshop, 2017. </li>
		    <br>

		    <li><strong>MSR Video to Language Challenge. </strong> 
		    <a href="https://ningxu1990.github.io/Ning_Xu_files/One_Page_16.pdf" target="_blank" rel="external">[PDF]</a><br>
              <em><strong>Ning Xu</strong>, Junnan Li, Yang Li, An-An Liu, Yongkang Wong, Weizhi Nie, Yuting Su, Mohan S. Kankanhalli. </em><br>
            Microsoft Research Video to Text (MSR-VTT) Challenge, 2016. </li>
		    <br>
		  
            <li><strong>TJU-TJUT@TRECVID 2015: Surveillance Event Detection. </strong>
			<a href="http://www-nlpir.nist.gov/projects/tvpubs/tv15.papers/tju-tjut.pdf" target="_blank" rel="external">[PDF]</a><br />
              <em>Yuting Su, An-An Liu*, Zan Gao, Weizhi Nie, <strong>Ning Xu</strong>, Fuwu Li. </em><br />
              TRECVID Challenge Workshop, 2015. </li>
          </ul>

      </div>
	  

</div>
</div>
	

	
</div>
	
<div id="footer">
	
	<!--HTMLFooter-->
</div>


</body></html>