<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<!-- saved from url=(0044)https://cs.nyu.edu/~fergus/pmwiki/pmwiki.php -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	<title>Ning Xu - HomePage </title>
	<meta http-equiv="Content-Style-Type" content="text/css">
	<!--HTMLHeader--><style type="text/css">
	<!--
  ul, ol, pre, dl, p { margin-top:0px; margin-bottom:0px; }
  code.escaped { white-space: nowrap; }
  .vspace { margin-top:1.33em; }
  .indent { margin-left:40px; }
  .outdent { margin-left:40px; text-indent:-40px; }
  a.createlinktext { text-decoration:none; border-bottom:1px dotted gray; }
  a.createlink { text-decoration:none; position:relative; top:-0.5em;
    font-weight:bold; font-size:smaller; border-bottom:none; }
  img { border:0px; }
  .editconflict { color:green; 
  font-style:italic; margin-top:1.33em; margin-bottom:1.33em; }

  table.markup { border:2px dotted #ccf; width:90%; }
  td.markup1, td.markup2 { padding-left:10px; padding-right:10px; }
  table.vert td.markup1 { border-bottom:1px solid #ccf; }
  table.horiz td.markup1 { width:23em; border-right:1px solid #ccf; }
  table.markup caption { text-align:left; }
  div.faq p, div.faq pre { margin-left:2em; }
  div.faq p.question { margin:1em 0 0.75em 0; font-weight:bold; }
  div.faqtoc div.faq * { display:none; }
  div.faqtoc div.faq p.question 
    { display:block; font-weight:normal; margin:0.5em 0 0.5em 20px; line-height:normal; }
  div.faqtoc div.faq p.question * { display:inline; }
   
    .frame 
      { border:1px solid #cccccc; padding:4px; background-color:#f9f9f9; }
    .lfloat { float:left; margin-right:0.5em; }
    .rfloat { float:right; margin-left:0.5em; }
a.varlink { text-decoration:none; }

-->
	</style>  <meta name="robots" content="index,follow">

	<link rel="stylesheet" href="https://ningxu1990.github.io/Publications/Ning%20Xu_files/pmwiki.css" type="text/css">
<style type="text/css">
<!--
#header {background-color: #134A86;}
a:link, a:visited, #menu ul li .here a, #menu ul li .here a:hover {color: #134A86;}
-->
</style>
<!--[if lte IE 6]>
<style type="text/css">
img, #logo, #vis, #header { behavior: url("https://cs.nyu.edu/~fergus/pmwiki/pub/skins/simpletab/iepngfix.htc"); }
</style>
<![endif]-->
	
</head><body><div id="page"><div id="suptitle"></div>
  <img src="Ning Xu_files/head.png" alt="" width="858" height="60" />  


	<div id="sidebar"><ul><li><a class="selflink" href="https://cs.nyu.edu/~fergus/pmwiki/pmwiki.php?n=Main.HomePage">Home</a>
<div class="vspace"></div></li>
<li><a class="wikilink" href="https://cs.nyu.edu/~fergus/pmwiki/pmwiki.php?n=PmWiki.Publications">Research</a></li>
<li><a class="wikilink" href="https://cs.nyu.edu/~fergus/pmwiki/pmwiki.php?n=PmWiki.Publications">Publications</a></li>
<li><a class="wikilink" href="https://cs.nyu.edu/~fergus/pmwiki/pmwiki.php?n=PmWiki.Students">Students</a></li>
<li><a class="wikilink" href="https://cs.nyu.edu/~fergus/pmwiki/pmwiki.php?n=PmWiki.Teaching">Teaching</a></li>
<li><a class="wikilink" href="https://cs.nyu.edu/~fergus/pmwiki/pmwiki.php?n=PmWiki.Bio">Bio</a></li></ul>
</div>
	
	<div id="content"><!--PageText-->
<div id="wikitext">
  <div class="vspace"></div>

<h1>Publications</h1>
<p align="justify">My papers can be found at:  
<a class="urllink" href="https://scholar.google.com/citations?user=GgQ9GEkAAAAJ&amp;hl=en&amp;oi=ao" rel="nofollow">Google Scholar</a> 
<br>

<hr>
<strong><font color="#4590a3" size="3px">Journal Articles</font></strong><br>
          <ul>
		  
		  <li><strong>Dual-Stream Recurrent Neural Network for Video Captioning. </strong> 
		  <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8447210" target="_blank" rel="external">[PDF]</a><br>
              <em><strong>Ning Xu</strong>, An-An Liu, Yongkang Wong, Yongdong Zhang, Weizhi Nie, Yuting Su, Mohan S. Kankanhalli. </em><br>
	      IEEE Transactions on Circuits and Systems for Video Technology, vol. 29, no. 8, pp. 2482-2493, 2019. <em>(IF=3.558)</em></li>
		  <br>

		  <li><strong>Hierarchical Deep Neural Network for Image Captioning. </strong> 
		  <a href="https://link.springer.com/content/pdf/10.1007%2Fs11063-019-09997-5.pdf" target="_blank" rel="external">[PDF]</a><br>
              <em>Yuting Su, Yuqian Li, <strong>Ning Xu</strong>, An-An Liu. </em><br>
	      Neural Processing Letters, 2019. <em>(IF=1.787)</em></li>
		  <br>
		  
		  <li><strong>Multi-Guiding Long-Short Term Memory for Video Captioning. </strong> 
		  <a href="https://link.springer.com/article/10.1007%2Fs00530-018-0598-5" target="_blank" rel="external">[PDF]</a><br>
              <em><strong>Ning Xu</strong>, An-An Liu, Weizhi Nie, Yuting Su. </em><br>
	      Multimedia Systems,  vol. 25, no. 6, pp. 663-672, 2019. <em>(IF=1.703)</em></li>
		  <br>

		  <li><strong>Multi-Domain and Multi-Task Learning for Human Action Recognition. </strong> 
		  <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8476540" target="_blank" rel="external">[PDF]</a><br>
              <em>An-An Liu, <strong>Ning Xu</strong>, Weizhi Nie, Yuting Su, Yongdong Zhang. </em><br>
	      IEEE Transactions on Image Processing, vol. 28, no. 2, pp. 853-867, 2019. <em>(IF=5.071)</em></li>
		  <br>
		  
		  <li><strong>Scene graph captioner: Image captioning based on structural visual representation. </strong> 
		  <a href="https://pdf.sciencedirectassets.com/272324/1-s2.0-S1047320318X0008X/1-s2.0-S1047320318303535/main.pdf?x-amz-security-token=AgoJb3JpZ2luX2VjEMb%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJGMEQCIAGani8d37fKLndZ1EQjPNTV2%2BYfKuHvDzyJwBKHPV7bAiAvB0a6dwB94EukccLMfPvL1aWCLodC1ysvIO3cspq%2BXirjAwiP%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAIaDDA1OTAwMzU0Njg2NSIMO0uPhYlu2hU4ve9QKrcDUiVzXPOJoQH%2FC%2BYJt8O05V5Mp42uCDRS5xGVRyr71Zq4NwqeFrsIhdBWBXDp5qVyvG87eYPvLLYYUEPdtQbFx%2BRIwIHOfXvlrHVfSUtUnTRIZovRvmbQktVGu%2Bu5OLXebP5BZpgF8c6cIghwjq8URe8W2jANoiIRo5PYrFXPK3pFxRbo9PLDZklYGZT8bJZA1M3Ed13sb8gQ3RpRctAWpJFpbx452YyBuBmy4XuQJJtfc3HPfN%2BlpiriVIpjE75bM1%2FzVD9dNKo490uge0E4RWp1SeTEd9YjyVcMxQgukv4OixTwUZme7q%2BTCbe%2Fk3W3zjzSlevQbuEtrt12FshaqdyCRo05U2vhL9G5iQCLNSv%2BZqugfCubuVaQOk8RCWmqeOudImlploKb8L9hQKseHlfkTTJCjlk3591q1xn7%2FwKKNIVuXTI2CF8AsSsP%2BqlxH7pb%2BJL3FpXJhHXnq%2F4t6YbVn1uc14obbg5%2BDE5pdqoihGDQOa7Je7imTKYj3HsH8xyMXesID8FDGfo1wxwLJFdbBJyqI5s0TiN5e37%2BLNPeimdtZsgtFumFiAvtY19QsKc6ArTXszD%2BgL3lBTq1AS5zYJhl7vMRZYU2YGNB1eBzpL67%2Fkh%2BmAOOoHpjiV7gsKzHzY%2FEiNjHsampS3cehW8COiP1NWyEOT98%2BAZsCAbFVWqm5CZQrSSIyN3EO1KWM0TCgKngi5B8Avm9oh5mVknN0dKOnIX%2B%2BOfni206UNgGABaPhZGX0w41I%2Bz4X1orgzfLUtC6x2zOucgzfAVfZE5uCIskBDpFvbfsKJDSQPuCOJ0b4HB34X3Y%2BpRv3%2B9pWB6aS0U%3D&AWSAccessKeyId=ASIAQ3PHCVTYX4XVCWWG&Expires=1554991643&Signature=XKPg8T7LNdlum6TQZU3%2FYa9VrE4%3D&hash=67a734fa1b32320c63f6a9299ba2fc80078fd0917626dbc4278c9a9ffaf0d38a&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S1047320318303535&tid=spdf-bbe73759-e213-4b27-917a-713bf17d4706&sid=a9226d812776644c466b62a461e9d07eb9f3gxrqa&type=client" target="_blank" rel="external">[PDF]</a><br>
              <em><strong>Ning Xu</strong>, An-An Liu, Jing Liu, Weizhi Nie, Yuting Su. </em><br>
	      Journal of Visual Communication and Image Representation, vol. 58, pp. 477-485, 2019. <em>(IF=1.836)</em></li>
		  <br>

		  <li><strong>Attention-in-Attention Networks for Surveillance Video Understanding in Internet of Things. </strong> 
		  <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8141866" target="_blank" rel="external">[PDF]</a><br>
              <em><strong>Ning Xu</strong>, An-An Liu, Weizhi Nie, Yuting Su. </em><br>
	      IEEE Internet of Things Journal, vol. 5, no. 5, pp. 3419-3429, 2018. <em>(IF=5.863)</em></li>
		  <br>
		  
		  <li><strong>Hierarchical &amp; Multimodal Video Captioning: Discovering and Transferring Multimodal Knowledge for Vision to Language. </strong> 
		  <a href="http://www.sciencedirect.com/science/article/pii/S1077314217300735/pdfft?md5=4b8580ed4f56eb06185af1c0ea1cc6b5&pid=1-s2.0-S1077314217300735-main.pdf" target="_blank" rel="external">[PDF]</a><br>
              <em>An-An Liu, <strong>Ning Xu</strong>, Yongkang Wong, Junnan Li, Yuting Su, Mohan S. Kankanhalli. </em><br>
	      Computer Vision and Image Understanding, vol. 163, pp. 113-125, 2017. <em>(IF=2.391)</em></li>
		  <br>
		  
          <li><strong>Benchmarking a Multi-modal &amp; Multi-view &amp; Interactive Dataset for Human Action Recognition. </strong> 
		  <a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7515012" target="_blank" rel="external">[PDF]</a><br />
            <em>An-An Liu, <strong>Ning Xu</strong>, Weizhi Nie, Yuting Su, Yongkang Wong, Mohan S. Kankanhalli. </em><br />
          IEEE Transactions on Cybernetics, vol. 47, no. 7, pp. 1781-1794, 2017.  <em>(IF=8.803)</em></li>
		  <br>
		  
          <li><strong>Single/multi-view human action recognition via regularized multi-task learning. </strong> 
		  <a href="https://ac.els-cdn.com/S0925231214013885/1-s2.0-S0925231214013885-main.pdf?_tid=af7489bc-e490-11e7-b3a1-00000aab0f01&acdnat=1513669753_ede107059bae358242aa059181fafba9" target="_blank" rel="external">[PDF]</a><br />
            <em>An-An Liu, <strong>Ning Xu</strong>, Yuting Su, Hong Lin, Tong Hao, Zhaoxuan Yang. </em><br />
          Neurocomputing, vol. 151, pp. 544-553, 2014.  <em>(IF=3.241)</em></li>
          </ul>
		  
        <br>
		<strong><font color="#4590a3" size="3px">Conference Papers</font></strong>
           <ul>
		   
           <li><strong>Multi-Level Policy and Reward Reinforcement Learning for Image Captioning. </strong> 
		   <a href="https://www.ijcai.org/proceedings/2018/114" target="_blank" rel="external">[PDF]</a><br />
               <em>An-An Liu, <strong>Ning Xu</strong>, Hanwang Zhang, Weizhi Nie, Yuting Su, Yongdong Zhang. </em><br />
             IJCAI, pp. 821-827, 2018.  <em>(CCF-A)</em></li>
           <br>
		   
           <li><strong>A Multi-modal &amp; Multi-view &amp; Interactive Benchmark Dataset for Human Action Recognition. </strong> 
		   <a href="http://delivery.acm.org/10.1145/2810000/2806315/p1195-xu.pdf?ip=202.113.11.104&id=2806315&acc=ACTIVE%20SERVICE&key=BF85BBA5741FDC6E%2EE4E04C281054793F%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&CFID=1018008020&CFTOKEN=25206131&__acm__=1513667603_35754e7fb63234465d9b5f7b2d537b36" target="_blank" rel="external">[PDF]</a><br />
               <em><strong>Ning Xu</strong>, An-An Liu, Weizhi Nie, Yongkang Wong, Fuwu Li, Yuting Su. </em><br />
             ACM Multimedia, pp. 1195-1198, 2015.  <em>(CCF-A)</em></li>
           </ul>
		   
        <br>
		<strong><font color="#4590a3" size="3px">Techinical Reports</font></strong><br>
          <ul>
		  
		    <li><strong>TJU-NUS@TRECVID 2017: Video to Text Description. </strong> 
		    <a href="http://www-nlpir.nist.gov/projects/tvpubs/tv17.papers/tju.pdf" target="_blank" rel="external">[PDF]</a><br>
              <em>An-An Liu, Yurui Qiu, Yongkang Wong, <strong>Ning Xu</strong>, Yuting Su, Mohan S. Kankanhalli.</em><br>
            TRECVID Challenge Workshop, 2017. </li>
		    <br>

		    <li><strong>MSR Video to Language Challenge. </strong> 
		    <a href="files/One_Page_16.pdf" target="_blank" rel="external">[PDF]</a><br>
              <em><strong>Ning Xu</strong>, Junnan Li, Yang Li, An-An Liu, Yongkang Wong, Weizhi Nie, Yuting Su, Mohan S. Kankanhalli. </em><br>
            Microsoft Research Video to Text (MSR-VTT) Challenge, 2016. </li>
		    <br>
		  
            <li><strong>TJU-TJUT@TRECVID 2015: Surveillance Event Detection. </strong>
			<a href="http://www-nlpir.nist.gov/projects/tvpubs/tv15.papers/tju-tjut.pdf" target="_blank" rel="external">[PDF]</a><br />
              <em>Yuting Su, An-An Liu, Zan Gao, Weizhi Nie, <strong>Ning Xu</strong>, Fuwu Li. </em><br />
              TRECVID Challenge Workshop, 2015. </li>
          </ul>

      </div>
	  

</div>
</div>
	

	
</div>
	
<div id="footer">
	
	<!--HTMLFooter-->
</div>


</body></html>