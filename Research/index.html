<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<!-- saved from url=(0044)https://cs.nyu.edu/~fergus/pmwiki/pmwiki.php -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	<title>Ning Xu - Research </title>
	<meta http-equiv="Content-Style-Type" content="text/css">
	<!--HTMLHeader--><style type="text/css">
	<!--
  ul, ol, pre, dl, p { margin-top:0px; margin-bottom:0px; }
  code.escaped { white-space: nowrap; }
  .vspace { margin-top:1.33em; }
  .indent { margin-left:40px; }
  .outdent { margin-left:40px; text-indent:-40px; }
  a.createlinktext { text-decoration:none; border-bottom:1px dotted gray; }
  a.createlink { text-decoration:none; position:relative; top:-0.5em;
    font-weight:bold; font-size:smaller; border-bottom:none; }
  img { border:0px; }
  .editconflict { color:green; 
  font-style:italic; margin-top:1.33em; margin-bottom:1.33em; }

  table.markup { border:2px dotted #ccf; width:90%; }
  td.markup1, td.markup2 { padding-left:10px; padding-right:10px; }
  table.vert td.markup1 { border-bottom:1px solid #ccf; }
  table.horiz td.markup1 { width:23em; border-right:1px solid #ccf; }
  table.markup caption { text-align:left; }
  div.faq p, div.faq pre { margin-left:2em; }
  div.faq p.question { margin:1em 0 0.75em 0; font-weight:bold; }
  div.faqtoc div.faq * { display:none; }
  div.faqtoc div.faq p.question 
    { display:block; font-weight:normal; margin:0.5em 0 0.5em 20px; line-height:normal; }
  div.faqtoc div.faq p.question * { display:inline; }
   
    .frame 
      { border:1px solid #cccccc; padding:4px; background-color:#f9f9f9; }
    .lfloat { float:left; margin-right:0.5em; }
    .rfloat { float:right; margin-left:0.5em; }
a.varlink { text-decoration:none; }

-->
	</style>  <meta name="robots" content="index,follow">

	<link rel="stylesheet" href="https://ningxu1990.github.io/Ning_Xu_files/pmwiki.css" type="text/css">
<style type="text/css">
<!--
#header {background-color: #134A86;}
a:link, a:visited, #menu ul li .here a, #menu ul li .here a:hover {color: #134A86;}
-->
</style>
<!--[if lte IE 6]>
<style type="text/css">
img, #logo, #vis, #header { behavior: url("https://cs.nyu.edu/~fergus/pmwiki/pub/skins/simpletab/iepngfix.htc"); }
</style>
<![endif]-->
	
</head><body><div id="page"><div id="suptitle"></div>
  <img src="https://ningxu1990.github.io/Ning_Xu_files/head.png" alt="" width="858" height="60" />  


<div id="sidebar"><ul><li><a class="selflink" href="https://ningxu1990.github.io">Home</a>
<div class="vspace"></div></li>
<li><a class="wikilink" href="https://ningxu1990.github.io/Research">Research</a></li>
<li><a class="wikilink" href="https://ningxu1990.github.io/Publications">Publications</a></li>
<li><a class="wikilink" href="https://ningxu1990.github.io/Students">Students</a></li>
<li><a class="wikilink" href="https://ningxu1990.github.io/Teaching">Teaching</a></li>
<li><a class="wikilink" href="https://ningxu1990.github.io/Bio">Bio</a></li></ul>
</div>
	
	<div id="content"><!--PageText-->
<div id="wikitext">
  <div class="vspace"></div>

<h1>Research</h1>

<p align="justify">&nbsp;</p>
 
<br>

	    <table border="0">
	      <tbody><tr><td width="220"><img border="0" src="https://ningxu1990.github.io/Ning_Xu_files/Research_image_captioning.jpg" alt="" width="200" height="130"></td>
		<td>
		  <p align="justify" class="bodyText style4">

 	            <strong>Image captioning</strong> is an exciting research area that lies at the intersection of computer vision and natural language processing. This task aims to automatically generate textual descriptions - i.e., captions - that accurately and naturally describe the content of images.

		  <br><br>
	    </p></td></tr></tbody></table><br>
		
		
	    <table border="0">
	      <tbody><tr><td width="220"><img border="0" src="https://ningxu1990.github.io/Ning_Xu_files/Research_text_to_image.png" alt="" width="200" height="130"></td>
		<td>
		  <p align="justify" class="bodyText style4">
		  
		  <strong>Text-to-image</strong> focuses on the generation of photorealistic images from given textual descriptions. It has applications across diverse domains, including the digital art, the educational content creation, and the interactive media. 
		  
		  <br><br>
	    </p></td></tr></tbody></table><br>
		

	    <table border="0">
	      <tbody><tr><td width="220"><img border="0" src="https://ningxu1990.github.io/Ning_Xu_files/Research_scene_graph_generation.png" alt="" width="200" height="160"></td>
		<td>
		  <p align="justify" class="bodyText style4">
		  
          <strong>Scene graph generation</strong> aims to create the structured representations of visual scenes. It interprets objects within images and categorizes their relationships, transforming a raw visual input into a graph-based format. Such representations are essential for enhancing machine understanding of complex scenes and enabling more intuitive interactions between AI and the visual world. 

		  <br>
		  <br>
	    </p></td></tr></tbody></table><br>
		
		
	    <table border="0">
	      <tbody><tr><td width="220"><img border="0" src="https://ningxu1990.github.io/Ning_Xu_files/Research_VQA.png" alt="" width="200" height="110"></td>
		<td>
		  <p align="justify" class="bodyText style4">
		  
		  <strong>Visual question answering</strong> is to combine computer vision and natural language processing to answer questions based on visual input. It involves interpreting visual content, such as images or videos, and providing accurate answers to textual queries related to the visual elements. 
		  
		  <br>
		  <br>
	    </p></td></tr></tbody></table><br>
		

	    <table border="0">
	      <tbody><tr><td width="220"><img border="0" src="https://ningxu1990.github.io/Ning_Xu_files/Research_Visual_Dialog.png" alt="" width="200" height="130"></td>
		<td>
		  <p align="justify" class="bodyText style4">
		  
		  <strong>Visual dialog</strong> aims to answer the current question, given an image, its caption and multi-round Q&A pairs, i.e., dialog history. By engaging in a dialog about visual content, AI systems learn to process and respond to a series of related questions, enhancing their ability to understand complex scenarios and nuances in human queries. 
		  
		  <br>
		  <br>
	    </p></td></tr></tbody></table><br>
		

<hr>


      </div>
	  

</div>
</div>
	

	
</div>
	
<div id="footer">
	
	<!--HTMLFooter-->
</div>


</body></html>