<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<!-- saved from url=(0032)http://www.ee.cuhk.edu.hk/~xchu/ -->
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

	<title>Ning Xu</title>
	<style>

@media screen and (max-device-width: 480px){
  body{
    -webkit-text-size-adjust: none;
  }
}
p { font-size : 16px; }
h1 { padding : 0; margin : 0; font-size : 34px; }
h2 { font-size : 20px; margin : 0; padding : 0; }
body { padding : 0; font-family : Arial; font-size : 16px; background-color : #FFFFFF; }
.title { width : 650px; margin : 20px auto; }
.container { width : 800px; margin : 20px auto; border-radius: 10px;  background-color : #fff; padding : 20px;  clear:both;}
#bio {
    padding-top : 40px;
}
#me { border : 0 solid black; margin-bottom : 50px; border-radius : 10px; }
#sidebar { margin-left : 25px; border : 0 solid black; float : right; margin-bottom : 0;}
a { text-decoration : none; }
a:hover { text-decoration : underline; }
a, a:visited { color : #0050e7; }
.publogo { width: 100 px; margin-right : 30px; margin-left : 30px; float : left; border : 0;}
.publication { clear : left; padding-bottom : 0px; }
.publication p { height : 100px; padding-top : 5px;}
.publication strong a { color : #0000A0; }
.publication .links { position : relative; top : 15px }
.publication .links a { margin-right : 20px; }
.codelogo { margin-right : 10px; float : left; border : 0;}
.code { clear : left; padding-bottom : 10px; vertical-align :middle;} 
.code .download a { display : block; margin : 0 15px; float : left;}
.code strong a { color : #000; }
.external a { margin : 0 10px; }
.external a.first { margin : 0 10px 0 0; }
	.STYLE5 {font-family: "宋体"}
    </style>
	<script async="" src="./Ning Xu&#39;s homepage_files/analytics.js"></script>
</head>

<body>
	<div class="title">
		<div id="sidebar"><img src="files/profile.jpg" vspace="16 px" width="260 px" id="profile" itemprop="photo"></div>
		<div id="bio">
			<h1>
				<span itemprop="name">Ning Xu (<span class="STYLE5">徐 宁</span>)</span>			</h1>
			<p style="line-height:25px;">
				Final Year Ph.D. Candidate<br> 
                Supervised by Professor <a href="http://www.tju.edu.cn/seea/szdw/xxx/201703/t20170322_292374.htm">An-An Liu</a><br>
                Tianjin University <br>
                
                Email: ningxustronger@gmail.com		  </p>
			<p class="external">
            <a href="https://github.com/ningxu1990" class="first">[GitHub]</a>
            <!--	<a href="https://scholar.google.com.hk/citations?user=R-VLSLQAAAAJ&amp;hl=en" class="first">[Google Scholar]</a>  -->
			</p>
		</div>
	</div>

	<div class="container">
		<!-- <h2>Short Bio</h2> -->
		<p align="justify"> 
I am currently pursuing my Ph.D. degree, supervised by Professor <a href="http://www.tju.edu.cn/seea/szdw/xxx/201703/t20170322_292374.htm">An-An Liu</a> at Tianjin University in China. I am a member of the <a href="http://m2i.ac.cn/">Multimedia Institute</a>.  
I was a visiting scholar from Mar. 2016 to Mar. 2017 at the <a href="http://sesame.comp.nus.edu.sg/">SeSaMe Research Centre</a> of NUS, working with Dr. <a href="https://sites.google.com/site/yongkangwong/">Yongkang Wong</a>. 
My recent research interests include computer vision, action recognition, relation detection, and vision captioning.  
I received my M.E. degree from Tianjin University in 2015 and B.E. degree from Hainan University (Advanced Class) in 2013.</p>
</div>

	<div class="container">
		<p><h2>Publications</h2></p>
		<br>
		
        <div class="publication">
		
		<strong><font color="#4590a3" size="4px">Journal Articles</font></strong><br>
          <ul>
		  
		  <li><strong>Dual-Stream Recurrent Neural Network for Video Captioning. </strong> 
		  <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8447210" target="_blank" rel="external">[PDF]</a><br>
              <em><strong>Ning Xu</strong>, An-An Liu, Yongkang Wong, Yongdong Zhang, Weizhi Nie, Yuting Su, Mohan S. Kankanhalli. </em><br>
	      IEEE Transactions on Circuits and Systems for Video Technology, 2019. <em>(IF=3.558)</em></li>
		  <br>

		  <li><strong>Hierarchical Deep Neural Network for Image Captioning. </strong> 
		  <a href="https://link.springer.com/content/pdf/10.1007%2Fs11063-019-09997-5.pdf" target="_blank" rel="external">[PDF]</a><br>
              <em>Yuting Su, Yuqian Li, <strong>Ning Xu</strong>, An-An Liu. </em><br>
	      Neural Processing Letters, 2019. <em>(IF=1.787)</em></li>
		  <br>
		  
		  <li><strong>Multi-Guiding Long-Short Term Memory for Video Captioning. </strong> 
		  <a href="https://link.springer.com/article/10.1007%2Fs00530-018-0598-5" target="_blank" rel="external">[PDF]</a><br>
              <em><strong>Ning Xu</strong>, An-An Liu, Weizhi Nie, Yuting Su. </em><br>
	      Multimedia Systems, 2019. <em>(IF=1.703)</em></li>
		  <br>

		  <li><strong>Multi-Domain and Multi-Task Learning for Human Action Recognition. </strong> 
		  <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8476540" target="_blank" rel="external">[PDF]</a><br>
              <em>An-An Liu, <strong>Ning Xu</strong>, Weizhi Nie, Yuting Su, Yongdong Zhang. </em><br>
	      IEEE Transactions on Image Processing, vol. 28, no. 2, pp. 853-867, 2019. <em>(IF=5.071)</em></li>
		  <br>
		  
		  <li><strong>Scene graph captioner: Image captioning based on structural visual representation. </strong> 
		  <a href="https://pdf.sciencedirectassets.com/272324/1-s2.0-S1047320318X0008X/1-s2.0-S1047320318303535/main.pdf?x-amz-security-token=AgoJb3JpZ2luX2VjEMb%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJGMEQCIAGani8d37fKLndZ1EQjPNTV2%2BYfKuHvDzyJwBKHPV7bAiAvB0a6dwB94EukccLMfPvL1aWCLodC1ysvIO3cspq%2BXirjAwiP%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAIaDDA1OTAwMzU0Njg2NSIMO0uPhYlu2hU4ve9QKrcDUiVzXPOJoQH%2FC%2BYJt8O05V5Mp42uCDRS5xGVRyr71Zq4NwqeFrsIhdBWBXDp5qVyvG87eYPvLLYYUEPdtQbFx%2BRIwIHOfXvlrHVfSUtUnTRIZovRvmbQktVGu%2Bu5OLXebP5BZpgF8c6cIghwjq8URe8W2jANoiIRo5PYrFXPK3pFxRbo9PLDZklYGZT8bJZA1M3Ed13sb8gQ3RpRctAWpJFpbx452YyBuBmy4XuQJJtfc3HPfN%2BlpiriVIpjE75bM1%2FzVD9dNKo490uge0E4RWp1SeTEd9YjyVcMxQgukv4OixTwUZme7q%2BTCbe%2Fk3W3zjzSlevQbuEtrt12FshaqdyCRo05U2vhL9G5iQCLNSv%2BZqugfCubuVaQOk8RCWmqeOudImlploKb8L9hQKseHlfkTTJCjlk3591q1xn7%2FwKKNIVuXTI2CF8AsSsP%2BqlxH7pb%2BJL3FpXJhHXnq%2F4t6YbVn1uc14obbg5%2BDE5pdqoihGDQOa7Je7imTKYj3HsH8xyMXesID8FDGfo1wxwLJFdbBJyqI5s0TiN5e37%2BLNPeimdtZsgtFumFiAvtY19QsKc6ArTXszD%2BgL3lBTq1AS5zYJhl7vMRZYU2YGNB1eBzpL67%2Fkh%2BmAOOoHpjiV7gsKzHzY%2FEiNjHsampS3cehW8COiP1NWyEOT98%2BAZsCAbFVWqm5CZQrSSIyN3EO1KWM0TCgKngi5B8Avm9oh5mVknN0dKOnIX%2B%2BOfni206UNgGABaPhZGX0w41I%2Bz4X1orgzfLUtC6x2zOucgzfAVfZE5uCIskBDpFvbfsKJDSQPuCOJ0b4HB34X3Y%2BpRv3%2B9pWB6aS0U%3D&AWSAccessKeyId=ASIAQ3PHCVTYX4XVCWWG&Expires=1554991643&Signature=XKPg8T7LNdlum6TQZU3%2FYa9VrE4%3D&hash=67a734fa1b32320c63f6a9299ba2fc80078fd0917626dbc4278c9a9ffaf0d38a&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S1047320318303535&tid=spdf-bbe73759-e213-4b27-917a-713bf17d4706&sid=a9226d812776644c466b62a461e9d07eb9f3gxrqa&type=client" target="_blank" rel="external">[PDF]</a><br>
              <em><strong>Ning Xu</strong>, An-An Liu, Jing Liu, Weizhi Nie, Yuting Su. </em><br>
	      Journal of Visual Communication and Image Representation, vol. 58, pp. 477-485, 2019. <em>(IF=1.836)</em></li>
		  <br>

		  <li><strong>Attention-in-Attention Networks for Surveillance Video Understanding in Internet of Things. </strong> 
		  <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8141866" target="_blank" rel="external">[PDF]</a><br>
              <em><strong>Ning Xu</strong>, An-An Liu, Weizhi Nie, Yuting Su. </em><br>
	      IEEE Internet of Things Journal, vol. 5, no. 5, pp. 3419-3429, 2018. <em>(IF=5.863)</em></li>
		  <br>
		  
		  <li><strong>Hierarchical &amp; Multimodal Video Captioning: Discovering and Transferring Multimodal Knowledge for Vision to Language. </strong> 
		  <a href="http://www.sciencedirect.com/science/article/pii/S1077314217300735/pdfft?md5=4b8580ed4f56eb06185af1c0ea1cc6b5&pid=1-s2.0-S1077314217300735-main.pdf" target="_blank" rel="external">[PDF]</a><br>
              <em>An-An Liu, <strong>Ning Xu</strong>, Yongkang Wong, Junnan Li, Yuting Su, Mohan S. Kankanhalli. </em><br>
	      Computer Vision and Image Understanding, vol. 163, pp. 113-125, 2017. <em>(IF=2.391)</em></li>
		  <br>
		  
          <li><strong>Benchmarking a Multi-modal &amp; Multi-view &amp; Interactive Dataset for Human Action Recognition. </strong> 
		  <a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7515012" target="_blank" rel="external">[PDF]</a><br />
            <em>An-An Liu, <strong>Ning Xu</strong>, Weizhi Nie, Yuting Su, Yongkang Wong, Mohan S. Kankanhalli. </em><br />
          IEEE Transactions on Cybernetics, vol. 47, no. 7, pp. 1781-1794, 2017.  <em>(IF=8.803)</em></li>
		  <br>
		  
          <li><strong>Single/multi-view human action recognition via regularized multi-task learning. </strong> 
		  <a href="https://ac.els-cdn.com/S0925231214013885/1-s2.0-S0925231214013885-main.pdf?_tid=af7489bc-e490-11e7-b3a1-00000aab0f01&acdnat=1513669753_ede107059bae358242aa059181fafba9" target="_blank" rel="external">[PDF]</a><br />
            <em>An-An Liu, <strong>Ning Xu</strong>, Yuting Su, Hong Lin, Tong Hao, Zhaoxuan Yang. </em><br />
          Neurocomputing, vol. 151, pp. 544-553, 2014.  <em>(IF=3.241)</em></li>
          </ul>
		  
        <br>
		<strong><font color="#4590a3" size="4px">Conference Papers</font></strong>
           <ul>
		   
           <li><strong>Multi-Level Policy and Reward Reinforcement Learning for Image Captioning. </strong> 
		   <a href="https://www.ijcai.org/proceedings/2018/114" target="_blank" rel="external">[PDF]</a><br />
               <em>An-An Liu, <strong>Ning Xu</strong>, Hanwang Zhang, Weizhi Nie, Yuting Su, Yongdong Zhang. </em><br />
             IJCAI, pp. 821-827, 2018.  <em>(CCF-A)</em></li>
           <br>
		   
           <li><strong>A Multi-modal &amp; Multi-view &amp; Interactive Benchmark Dataset for Human Action Recognition. </strong> 
		   <a href="http://delivery.acm.org/10.1145/2810000/2806315/p1195-xu.pdf?ip=202.113.11.104&id=2806315&acc=ACTIVE%20SERVICE&key=BF85BBA5741FDC6E%2EE4E04C281054793F%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&CFID=1018008020&CFTOKEN=25206131&__acm__=1513667603_35754e7fb63234465d9b5f7b2d537b36" target="_blank" rel="external">[PDF]</a><br />
               <em><strong>Ning Xu</strong>, An-An Liu, Weizhi Nie, Yongkang Wong, Fuwu Li, Yuting Su. </em><br />
             ACM Multimedia, pp. 1195-1198, 2015.  <em>(CCF-A)</em></li>
           </ul>
		   
        <br>
		<strong><font color="#4590a3" size="4px">Techinical Reports</font></strong><br>
          <ul>
		  
		    <li><strong>TJU-NUS@TRECVID 2017: Video to Text Description. </strong> 
		    <a href="http://www-nlpir.nist.gov/projects/tvpubs/tv17.papers/tju.pdf" target="_blank" rel="external">[PDF]</a><br>
              <em>An-An Liu, Yurui Qiu, Yongkang Wong, <strong>Ning Xu</strong>, Yuting Su, Mohan S. Kankanhalli.</em><br>
            TRECVID Challenge Workshop, 2017. </li>
		    <br>

		    <li><strong>MSR Video to Language Challenge. </strong> 
		    <a href="files/One_Page_16.pdf" target="_blank" rel="external">[PDF]</a><br>
              <em><strong>Ning Xu</strong>, Junnan Li, Yang Li, An-An Liu, Yongkang Wong, Weizhi Nie, Yuting Su, Mohan S. Kankanhalli. </em><br>
            Microsoft Research Video to Text (MSR-VTT) Challenge, 2016. </li>
		    <br>
		  
            <li><strong>TJU-TJUT@TRECVID 2015: Surveillance Event Detection. </strong>
			<a href="http://www-nlpir.nist.gov/projects/tvpubs/tv15.papers/tju-tjut.pdf" target="_blank" rel="external">[PDF]</a><br />
              <em>Yuting Su, An-An Liu, Zan Gao, Weizhi Nie, <strong>Ning Xu</strong>, Fuwu Li. </em><br />
              TRECVID Challenge Workshop, 2015. </li>
          </ul>

      </div>
	  
	  <br>
	  <p><h2>Honors & Awards<br>
		
        </h2>
	  <div class="honors_awards">
			<ul>
				<li>“Chu Xin” Scholarship, Tianjin University, 2018.</li><br>
				<li>First Prize for Academic Scholarship, Tianjin University, 2017.</li>
				<br>
				<li>First Prize for National Post-Graduate Mathematic Contest in Modeling, 2014.</li>
				<br>
			</ul>
	  </div>
		
	  <br>
	  <br>
	  <br>
	  <br>
	  <br>

					<div class="loose" display="inline-block">
					   <div align="center"><a href="http://m2i.ac.cn/"><img src="files/M2I_logo.png" width="80" height="70" class="footprint"></a>
					       <a href="http://www.tju.edu.cn/english/"><img src="files/TJU_logo.png" width="70" height="70" class="footprint"></a>
					       <a href="http://sesame.comp.nus.edu.sg/"><img src="files/SeSaMe_logo.png" width="180" height="70" class="footprint"></a>  
					       <a href="http://www.nus.edu.sg/"><img src="files/NUS_logo.png" width="150" height="70" class="footprint"></a>
					       <a href="https://www.hainanu.edu.cn/index.shtml"> <img src="files/HNU_logo.png" width="61" height="70" class="footprint"></a>
			          </div>
					</div>
		
	</div>  




<div class="sogoutip" style="z-index: 2147483645; visibility: hidden;"></div>
<div class="sogoubottom" id="sougou_bottom" style="display: block;"></div>
<div id="ext_stophi" style="z-index: 2147483647;"><div class="extnoticebg"></div><div class="extnotice"><p id="sogouconfirmtxt"></p></div></div>
<div id="ext_overlay" class="ext_overlayBG" style="display: none; z-index: 2147483646;"></div>
<iframe class="sogou_sugg_feedbackquan" frameborder="0" scrolling="no" style="border: none; display: block; height: 84px; width: 100%; z-index: 2147483645; background: transparent;"></iframe>

</body></html>